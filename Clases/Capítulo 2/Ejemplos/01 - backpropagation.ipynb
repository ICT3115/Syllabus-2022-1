{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase que representa un arco en el grafo de cómputo.\n",
    "# Almacena un valor propagado hacia adelante, y un gradiente\n",
    "# que es propagado hacia atrás.\n",
    "class Link:\n",
    "    def __init__(self, value, parent = None):\n",
    "        self.value = np.array(value)\n",
    "        self.__grad = np.zeros(self.value.shape)\n",
    "        self.__parent = parent\n",
    "    \n",
    "    def get_grad(self):\n",
    "        return np.copy(self.__grad)\n",
    "\n",
    "    def propagate_grad(self, grad):\n",
    "        self.__grad += grad\n",
    "        if self.__parent != None:\n",
    "            self.__parent.backward()\n",
    "    \n",
    "    def update_value(self, step_size):\n",
    "        self.value += step_size*self.__grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compuerta/Nodo que implementa una operación/función arbitraria.\n",
    "# Las compuertas son además las encargadas de propagar los valores y gradientes \n",
    "class AddGate:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.z = None\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = Link(self.x.value + self.y.value, self)\n",
    "        return self.z\n",
    "    def backward(self):\n",
    "        self.x.propagate_grad(1. * self.z.get_grad())\n",
    "        self.y.propagate_grad(1. * self.z.get_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulGate:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.z = None\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = Link(self.x.value * self.y.value, self)\n",
    "        return self.z\n",
    "    def backward(self):\n",
    "        self.x.propagate_grad(self.y.value * self.z.get_grad()) \n",
    "        self.y.propagate_grad(self.x.value * self.z.get_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SigmoidGate:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.z = None\n",
    "    def sigmoid(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.z = Link(SigmoidGate.sigmoid(self.x.value), self)\n",
    "        return self.z\n",
    "    def backward(self):\n",
    "        s = self.z.value\n",
    "        self.x.propagate_grad(s * (1-s) * self.z.get_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph definition (gates/nodes and links/edges)\n",
    "w0 = Link([2.0])\n",
    "w1 = Link([-3.0])\n",
    "w2 = Link([-3.0])\n",
    "x0 = Link([-1.0])\n",
    "x1 = Link([-2.0])\n",
    "\n",
    "mulg0 = MulGate()\n",
    "mulg1 = MulGate()\n",
    "addg0 = AddGate()\n",
    "addg1 = AddGate()\n",
    "sg0 = SigmoidGate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "def forwardNetwork():\n",
    "    prod1 = mulg0.forward(w0, x0)\n",
    "    prod2 = mulg1.forward(w1, x1)\n",
    "    res = addg0.forward(prod1, prod2)\n",
    "    res2 = addg1.forward(res, w2)\n",
    "    return  sg0.forward(res2)\n",
    "\n",
    "s = forwardNetwork()\n",
    "print('network output: ' + str(s.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "s.propagate_grad(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one step of gradient ascent\n",
    "step_size = 0.01;\n",
    "w0.update_value(step_size)\n",
    "w1.update_value(step_size)\n",
    "w2.update_value(step_size)\n",
    "x0.update_value(step_size)\n",
    "x1.update_value(step_size)\n",
    "\n",
    "s = forwardNetwork()\n",
    "print('network output after one step of gradient ascent: ' + str(s.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w0.get_grad())\n",
    "print(x0.get_grad())\n",
    "print(w1.get_grad())\n",
    "print(x1.get_grad())\n",
    "print(w2.get_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProdGate:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.z = None\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = Link(self.x.value.dot(self.y.value), self)\n",
    "        return self.z\n",
    "    def backward(self):\n",
    "        self.x.propagate_grad(self.y.value * self.z.get_grad())\n",
    "        self.y.propagate_grad(self.x.value * self.z.get_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value and gates definition\n",
    "w = Link([2.0,-3.0,-3.0])\n",
    "x = Link([-1.0, -2.0, 1.0])\n",
    "\n",
    "dp = DotProdGate()\n",
    "sg = SigmoidGate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardNetwork():\n",
    "    wx = dp.forward(w, x)\n",
    "    output = sg.forward(wx) \n",
    "    return output\n",
    "\n",
    "s = forwardNetwork()\n",
    "print('network output: ' + str(s.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward pass\n",
    "s.propagate_grad(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one step of gradient ascent\n",
    "step_size = 0.01;\n",
    "w.update_value(step_size) \n",
    "x.update_value(step_size)\n",
    "\n",
    "s = forwardNetwork()\n",
    "print('network output after one step of gradient ascent: ' + str(s.value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w.get_grad())\n",
    "print(x.get_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronGate:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.z = None\n",
    "    def sigmoid(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        dotProd = self.x.value.dot(self.y.value)\n",
    "        s = PerceptronGate.sigmoid(dotProd)\n",
    "        self.z = Link(s, self)\n",
    "        return self.z\n",
    "    def backward(self):\n",
    "        s = self.z.value\n",
    "        self.x.propagate_grad(self.y.value * s * (1 - s) * self.z.get_grad())\n",
    "        self.y.propagate_grad(self.x.value * s * (1 - s) * self.z.get_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossGate:\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "        self.z = None\n",
    "    def forward(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = Link(0.5*(self.x.value-self.y.value)**2, self)\n",
    "        return self.z\n",
    "    def backward(self):\n",
    "        self.x.propagate_grad((self.x.value-self.y.value) * self.z.get_grad())\n",
    "        self.y.propagate_grad(-1.0*(self.x.value-self.y.value) * self.z.get_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value and gates definition\n",
    "w = Link([2.0,-3.0,-3.0])\n",
    "x = Link([-1.0, -2.0, 1.0])\n",
    "y = Link(np.random.rand())\n",
    "\n",
    "perceptron = PerceptronGate()\n",
    "loss = LossGate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward pass\n",
    "def forwardNetwork():\n",
    "    p = perceptron.forward(w,x)\n",
    "    return loss.forward(p,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent\n",
    "step_size = 0.01;\n",
    "s = forwardNetwork()\n",
    "while s.value > 1e-3:\n",
    "    s.propagate_grad(1.0)\n",
    "    w.update_value(-step_size) \n",
    "    #x.update_value(-step_size)\n",
    "    s = forwardNetwork()\n",
    "    print('current loss: ' + str(s.value))\n",
    "    time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w.get_grad())\n",
    "print(x.get_grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
