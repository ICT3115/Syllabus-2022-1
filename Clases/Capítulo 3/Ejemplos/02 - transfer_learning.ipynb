{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZdauB_uvixt"
      },
      "source": [
        "# Transfer Learning\n",
        "\n",
        "En el siguiente ejemplo, utilizaremos redes neuronales convolucionales para categorizar imágenes en distintos conjuntos de datos, aplicando técnicas de _transfer learning_. Dado que es altamente complejo y lento entrenar una red convolucional en conjunto de datos grandes como ImageNet, es muy común transferir lo aprendido en ese conjunto a otros sets de datos afines. En este ejemplo en particular, exploraremos dos casos de transferencia para realizar clasificación de imágenes que contienen abejas u hormigas:\n",
        "- **Finetuning**: En vez de utilizar una inicialización aleatoria para los pesos de una red, inicializaremos los pesos (exceptuando los de la capa de clasificación) con los obtenidos para una ResNet18, después de haber sido entrenada en ImageNet. Luego de esto, el entrenamiento sigue como siempre.\n",
        "- **Feature extraction**: Similar al caso anterior, con la diferencia que el entrenamiento solo considera la optimización de los pesos de la nueva capa de clasificación, es decir, todo el resto de los pesos queda fijo e igual a los obtenidos por la ResNet18 entrenada en ImageNet.\n",
        "\n",
        "**IMPORTANTE**: al igual que en el ejemplo anterior, es importante que antes de ejecutar el código, estemos utilizando un _Runtime_ de tipo GPU. Para esto, deben seleccionar en el menú de arriba `Runtime -> Change Runtime Type -> GPU` y luego `Save`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_tmvevhv6tN"
      },
      "source": [
        "## 1. Importación de librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhZeTkbMyjFA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1AHvfZaylx9"
      },
      "outputs": [],
      "source": [
        "#estas instrucciones sirven para aumentar el tamaño de gráficos e imágenes\n",
        "plt.rcParams['figure.figsize'] = [15, 10]\n",
        "plt.rcParams.update({'font.size': 16})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LfIVV78tGTu"
      },
      "source": [
        "## 2. Carga, lectura y preprocesamiento de datos\n",
        "\n",
        "En este ejemplo utilizaremos el set de datos _hymenoptera_, que contiene imágenes de abejas y hormigas, que deben ser clasificadas. El conjunto considera para cada categoría, 120 imágenes de entrenamiento y 75 de validación. Dado el reducido tamaño de este conjunto, es imposible enternar una CNN desde cero con estos datos, sin sufrir de serios problemas de sobreentrenamiento. Esto lo hace un candidato ideal para aplicar conceptos de _transfer learning_.\n",
        "\n",
        "El primer paso consiste en descargar el set de datos y descomprimirlo, para lo que utilizamos los siguientes comandos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJseINmx-JJY"
      },
      "outputs": [],
      "source": [
        "!wget https://download.pytorch.org/tutorial/hymenoptera_data.zip\n",
        "!unzip hymenoptera_data.zip\n",
        "# es importante ejecutar esta celda solo una vez, de lo contrario se descargarán\n",
        "# los datos multiples veces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8uSA8-c0o_x"
      },
      "source": [
        "A continuación, definimos los `Dataset` y `DataLoader` respectivos (entrenamiento y validación), considerando una serie de transformaciones de las imágenes, con el fin de hacer _data augmentation_ y reducir el sobreentrenamiento. Un aspecto importante a destacar es que los coeficientes utilizados para redimensionar y normalizar las imágenes son derivados del entrenamiento de una ResNet18 en ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIlwSdt9tGTu"
      },
      "outputs": [],
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = 'hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=2)\n",
        "              for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRAsG566tGTv"
      },
      "source": [
        "A continuación visualizamos algunas de las imágenes, con el fin de notar algunas de las transformaciones resultantes del proceso de _data augmentation_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XH3XNkXgtGTv"
      },
      "outputs": [],
      "source": [
        "def imshow(input_data, title=None):\n",
        "    input_data = input_data.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    input_data = std * input_data + mean\n",
        "    input_data = np.clip(input_data, 0, 1)\n",
        "    plt.imshow(input_data)\n",
        "    plt.title(title)\n",
        "    #plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "imshow(out, title=[class_names[x] for x in classes])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGr6uaFLtGTv"
      },
      "source": [
        "## 3. Función de entrenamiento de los modelos\n",
        "\n",
        "Dado que evaluaremos dos esquemas de entrenamiento distintos, es conveniente encapsular el process, con el fin evitar la repetición de código.\n",
        "\n",
        "La función es similar a lo visto en los entrenamiento en ejemplos pasados, con la diferencia que acá se evalua el set de validación en cada época y se respalda el modelo que mejor rendimiento haya obtenido en el set de validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLP6cR_StGTw"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, device, num_epochs=25):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  \n",
        "            else:\n",
        "                model.eval()   \n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            total_examples = 0\n",
        "\n",
        "            with tqdm.notebook.tqdm(total=len(dataloaders[phase]), unit='batch', \n",
        "                                    desc=f'Epoch {epoch+1}/{num_epochs} stage {phase}', \n",
        "                                    position=100, leave=True) as pbar: \n",
        "              for inputs, labels in dataloaders[phase]:\n",
        "                  inputs = inputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "\n",
        "                  optimizer.zero_grad()\n",
        "\n",
        "                  with torch.set_grad_enabled(phase == 'train'):\n",
        "                      outputs = model(inputs)\n",
        "                      _, preds = torch.max(outputs, 1)\n",
        "                      loss = criterion(outputs, labels)\n",
        "\n",
        "                      if phase == 'train':\n",
        "                          loss.backward()\n",
        "                          optimizer.step()\n",
        "\n",
        "                  running_loss += loss.item() * inputs.size(0)\n",
        "                  running_corrects += torch.sum(preds == labels.data)\n",
        "                  total_examples += inputs.size(0)\n",
        "\n",
        "                  pbar.set_postfix(loss=running_loss/total_examples, \n",
        "                                   accuracy=running_corrects.item()/total_examples)\n",
        "                  pbar.update()\n",
        "\n",
        "              epoch_loss = running_loss / dataset_sizes[phase]\n",
        "              epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "              \n",
        "              # deep copy the model\n",
        "              if phase == 'val' and epoch_acc > best_acc:\n",
        "                  best_acc = epoch_acc\n",
        "                  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4VKFWkhtGTx"
      },
      "source": [
        "## 4. Finetuning\n",
        "\n",
        "Para realizar el proceso de _finetuning_, primero descargamos la ResNet18 preentrenada. Luego, intercambiamos su capa de clasificación por una nueva, con el fin de clasificar entre las 2 categorías disponibles. Finalmente, definimos el resto de los elementos necesarios para el entrenamiento (pérdida y optimizador) y luego llamamos a la función de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShDyLraXtGTx"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_ft = models.resnet18(pretrained=True)\n",
        "\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# notar que acá se le entregan todos los parámetros del modelo al optimizador\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "model_ft = train_model(model_ft, criterion, optimizer_ft, device, num_epochs=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXpaG3OftGTy"
      },
      "source": [
        "## 5. Feature Extraction\n",
        "\n",
        "Finalmente, evaluamos el segundo esquema de transferencia, al fijar los pesos de la red, mediante el uso de `requires_grad == False` en las capas de la ResNet18 y al pasar al optimizador solo los pesos de la capa lineal de clasificación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa0unxAXtGTy"
      },
      "outputs": [],
      "source": [
        "model_fe = torchvision.models.resnet18(pretrained=True)\n",
        "for param in model_fe.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "num_ftrs = model_fe.fc.in_features\n",
        "model_fe.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_fe = model_fe.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# notar que acá solo se pasan los pesos de la última capa densa\n",
        "optimizer_fe = optim.Adam(model_fe.fc.parameters(), lr=0.001)\n",
        "\n",
        "model_fe = train_model(model_fe, criterion, optimizer_fe, device, num_epochs=25)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "02 - transfer_learning.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.6 64-bit",
      "name": "python386jvsc74a57bd0432ee9dc30be07d38c29275a8ba4708057635a20469ddd67f0dfa942a950c372"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
