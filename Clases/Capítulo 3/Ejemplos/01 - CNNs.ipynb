{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "01 - CNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgUnwZ2haMif"
      },
      "source": [
        "# Redes neuronales para datos visuales \n",
        "En el siguiente ejemplo, utilizaremos redes neuronales convolucionales para categorizar imágenes, utilizando los pixeles de estas como _features_. Es importante, más que en el ejemplo de _embeddings_, que antes de ejecutar el código, estemos utilizando un _Runtime_ de tipo GPU. Para esto, deben seleccionar en el menú de arriba `Runtime -> Change Runtime Type -> GPU` y luego `Save`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5B8COoMaqNS"
      },
      "source": [
        "## 1. Importación de librerías\n",
        "Las librerías que utilizaremos en este ejemplo son similares a las del ejemplo de _embeddings_. La principal diferencia es que acá utilizaremos los modulos de Pytorch especializados en procesar imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ixM7xTP5yzu"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJHBZjlSqr9F"
      },
      "source": [
        "#estas instrucciones sirven para aumentar el tamaño de gráficos e imágenes\n",
        "plt.rcParams['figure.figsize'] = [15, 10]\n",
        "plt.rcParams.update({'font.size': 16})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pw_6llx_cIIr"
      },
      "source": [
        "## 2. Lectura y preprocesamiento de datos\n",
        "A diferencia de los casos anteriores, acá utilizaremos un set que viene precargado en Pytorch, lo que significa que no es necesario crear una clase derivada de `Dataset`.\n",
        "El set que usaremos es el CIFAR10, que contiene imágenes a color de 32x32 pixeles, pertencecientes a 10 categorías: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gMu2-MX5yz1"
      },
      "source": [
        "Un aspecto interesante de Pytorch es que permite definir una secuencia de transformaciones para los datos, de manera de automatizar ciertas partes del preprocesamiento. En este caso, dado que los pixeles  de las imágenes del set de datos viven en el rango [0,1], usaremos la composición definida en la siguiente celda, para crear una transformación que primero lleve las imágenes a tensores de Pytorch, y luego las lleve al rango [-1, 1].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnZKv3tA5yz2"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9ijR-ys4eyE"
      },
      "source": [
        "A continuación, definimos los sets de entrenamiento y test, junto con sus respectivos `DataLoaders`. Notemos que el set de datos es descargado directamente por Pytorch, sin requerir mayor intervención nuestra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfWnuo3c4fUT"
      },
      "source": [
        "batch_size = 256\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrhU_9OS5yz2"
      },
      "source": [
        "Finalmente, visualizamos algunas de las imágenes elegidas aleatoriamente. Es importante notar que para poder mostrarlas, es necesario denormalizar las imágenes (función `ishow`, línea 2).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVmeh8qF5yz3"
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "num_images = 8\n",
        "images = images[:num_images]\n",
        "labels = labels[:num_images]\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GT:\\t', (8*' ').join('%-6s' % classes[labels[j]] for j in range(num_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpOOvHMv5yz3"
      },
      "source": [
        "## 3. Definición del modelo\n",
        "Para procesar los datos, definimos una red con capas convolucionales densas, cuidando de hacer coincidir de manera adecuada la cantidad de filtros/neuronas de cada una (recuerden las fórmulas vistas en clase). Es importante notar que en el `forward`, luego de las primeras 2 capas convolucionales hay un _max pooling_, lo que afecta en la definición del tamaño de entrada de la primera capa densa.\n",
        "\n",
        "Un aspecto interesante es que antes de pasar las features a la primera capa densa, es necesario cambiar su forma (función `view`), para transformarlas en un vector unidimensional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWMMlODT5yz3"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 5)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
        "        self.conv3 = nn.Conv2d(32, 32, 3)\n",
        "        self.fc = nn.Linear(32 * 4 * 4, 64)\n",
        "        self.classifier = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = x.view(-1, 32 * 4 * 4)\n",
        "        x = F.relu(self.fc(x))\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp0Eo__55yz3"
      },
      "source": [
        "## 4. Instanciación del modelo, pérdida y optimizador\n",
        "Sin grandes misterios acá, instanciamos el modelo y lo enviamos a la GPU, y luego creamos la pérdida (_Cross entropy_ para clasificación) y el optimizador (Adam).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IgE3P0D5yz4"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = CNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxWPLmRJ5yz4"
      },
      "source": [
        "##5. Entrenamiento\n",
        "El entrenamiento sigue la misma lógica que el ejemplo anterior de Pytorch para datos tabulados, con pequeñas diferencias en la manera en que mostramos el avance del proceso. Con el fin de que no tome tanto el proceso, solo realizaremos 10 épocas de entrenamiento. Este número puede, y debe, modificarse para calibrar de mejor manera el rendimiento, siempre considerando un set de validación.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A7KrWG8Cg3s"
      },
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  total_loss = 0\n",
        "  total_examples = 0\n",
        "\n",
        "  with tqdm.notebook.tqdm(total=len(trainloader), unit='batch', desc=f'Epoch {epoch+1}/{num_epochs}', \n",
        "                          position=100, leave=True) as pbar:  \n",
        "    for X, Y in trainloader: \n",
        "\n",
        "      X = X.to(device)\n",
        "      Y = Y.to(device)\n",
        "\n",
        "      # Forward pass\n",
        "      Y_ = model(X)\n",
        "      loss = criterion(Y_, Y)\n",
        "\n",
        "      # Backward pass\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      # Gradient descent\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += loss.item()*X.size(0)\n",
        "      total_examples += X.size(0)\n",
        "\n",
        "      pbar.set_postfix(loss=total_loss/total_examples)\n",
        "      pbar.update()     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMbNGz5jDr65"
      },
      "source": [
        "##6. Evaluación\n",
        "A continuación evaluaremos el rendimiento del modelo recién entrenado. Nuestra primera tarea será visualizar algunas de sus predicciones. Es importante notar que, dado que la red predice una distribución de probabilidades sobre las 10 categorías (_softmax_), debemos reportar la categoría con mayor probabilidad (línea 2).  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPdBJZEREnfn"
      },
      "source": [
        "outputs = model(images.to(device))\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GT:\\t', (8*' ').join('%-6s' % classes[labels[j]] for j in range(num_images)))\n",
        "print('Pred:\\t', (8*' ').join('%-6s' % classes[predicted[j]] for j in range(num_images)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExK-2ze6Puaa"
      },
      "source": [
        "Como se aprecia, la red hace en general un trabajo razonable de predicción, a pesar de que algunas predicciones no tienen mucho sentido. Dado que las imágenes usadas son del mismo set de entrenamiento, es probable que más épocas permitan mejorar esto, potencialmente a costa de un mayor nivel de sobreentrenamiento.\n",
        "\n",
        "A continuación, evaluaremos el rendimiento en el set de test. Un elemento importante a considerar es que como métrica de rendimiento no utilizaremos la pérdida del modelo, sino algo más \"humanamente\" informativo como el _accuracy_ (razón entre correcciones correctas y elementos totales de una clase). Un detalle importante del _accuracy_ es que en su versión básica, no toma en consideración si una clase tiene más ejemplos que otra. Esto hace que en problemas con desbalance, esta métrica pueda lleva a engaño (solo la clase mayor está bien clasificada). Si bien en este caso las clases están balanceadas y basta con mantener la versión básica, implementaremos la versión balanceada, calculando primero el _accuracy_ por clase y luego promediándolos. Fuera de eso, el proceso es muy similar al realizado durante el entrenamiento.\n",
        "\n",
        "**ULTRA IMPORTANTE**: al evaluar, es fundamental cambiar el modelo a modo `eval`. Por un lado, esto permite que el modelo no sea modificable y que se gaste menos memoria, pero por otro lado esto hace que algunas capas (como las de _dropout_ o _batchnorm_), cambien su funcionamiento automaticamente al modo evaluación (no funcionan igual en entrenamiento y evaluación). No confundir las funcionalidades del método `eval()` con el método `torch.no_grad()`, que solo evita que se calcule el gradiente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73s_NtoZ5yz7"
      },
      "source": [
        "correct = [0]*len(classes)\n",
        "total = [0]*len(classes)\n",
        "acc = [0]*len(classes)\n",
        "\n",
        "model.eval()\n",
        "with tqdm.notebook.tqdm(total=len(testloader), unit='batch', desc=f'Evaluation', \n",
        "                        position=100, leave=True) as pbar:  \n",
        "  for X, Y in testloader: \n",
        "\n",
        "    X = X.to(device)\n",
        "    Y = Y.to(device)\n",
        "\n",
        "    _, Y_ = torch.max(model(X).data, 1)\n",
        "\n",
        "    for y, y_ in zip(Y, Y_):\n",
        "      if y == y_:\n",
        "          correct[y] += 1\n",
        "      total[y] += 1\n",
        "      acc[y] = correct[y]/total[y]\n",
        "\n",
        "    pbar.set_postfix(accuracy=sum(acc)/len(classes))\n",
        "    pbar.update()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3nx8cMf5yz7"
      },
      "source": [
        "Si bien el accuracy que logramos no se ve muy impresionante, si consideramos que la probabilidad de clasificar correctamente un ejemplo si se hace de manera aleatoria es de 0,1, entonces parece no ser tan malo.\n",
        "\n",
        "Finalmente, revisaremos el _accuracy_ por clase, con el fin de verificar si hay categorías más complejas que otras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLdG-r9X5yz7"
      },
      "source": [
        "for class_name,class_acc in zip(classes,acc):\n",
        "    print(f'Accuracy para la clase {class_name:5s}: {class_acc:.2f}')\n",
        "print(f'Accuracy promedio (balanceado): {sum(acc)/len(classes):.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBTxz4zupgFV"
      },
      "source": [
        "Podemos ver que hay una disparidad bastante grande en el _accuracy_ de cada clase, detacando lo bajo de _cat_ y lo alto de _car_ y _frog_. Queda como ejercicio propuesto el explorar manera de mejorar el rendimiento en test y el rendimiento en las clases más difíciles."
      ]
    }
  ]
}